# ‚úÖ Claude + OpenAI Setup Complete

## What Was Configured

The system is now set up to use **Claude (Anthropic) for agent reasoning** and **OpenAI for embeddings only**.

### Changes Made

1. **Updated Base Agent (`backend/src/agents/base.py`)**
   - Prioritizes Anthropic when both keys are present
   - Logs which LLM provider is being used
   - Clear separation: Claude for reasoning, OpenAI for embeddings

2. **Updated Vector Store (`backend/src/memory/vector_store.py`)**
   - Clarified that OpenAI is used for embeddings only
   - Added helpful warning messages when embeddings unavailable
   - Logs embedding provider selection

3. **Updated Environment Template (`.env.example`)**
   - Clearly marked recommended setup
   - Anthropic listed first (prioritized)
   - Explained purpose of each key

4. **Updated README.md**
   - Shows recommended Claude + OpenAI configuration
   - Links to detailed setup guide

5. **Created Comprehensive Setup Guide (`docs/CLAUDE_SETUP.md`)**
   - Detailed configuration instructions
   - Cost estimates
   - Troubleshooting guide
   - Best practices

## How to Configure

### Step 1: Get API Keys

**Anthropic:**
- Visit: https://console.anthropic.com/
- Create API key (starts with `sk-ant-`)

**OpenAI:**
- Visit: https://platform.openai.com/
- Create API key (starts with `sk-`)

### Step 2: Update .env

```bash
cp .env.example .env
```

Edit `.env`:
```bash
# Anthropic - for agent reasoning
ANTHROPIC_API_KEY=sk-ant-your-actual-key-here
ANTHROPIC_MODEL=claude-3-opus-20240229

# OpenAI - for embeddings only
OPENAI_API_KEY=sk-your-actual-key-here
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Snowflake
SNOWFLAKE_ACCOUNT=your_account.region
SNOWFLAKE_USER=your_user
SNOWFLAKE_PASSWORD=your_password
SNOWFLAKE_WAREHOUSE=your_warehouse
SNOWFLAKE_DATABASE=your_database
SNOWFLAKE_SCHEMA=your_schema
```

### Step 3: Start System

```bash
cd infrastructure
docker-compose up -d
docker exec -it dv360-backend alembic upgrade head
```

### Step 4: Verify

```bash
# Check logs
docker logs dv360-backend | grep "Using"

# You should see:
# INFO: Using Anthropic Claude for LLM model=claude-3-opus-20240229
# INFO: Using OpenAI for embeddings model=text-embedding-3-small
```

## What This Means

### Agent Conversations ‚úÖ
**Uses:** Claude (Anthropic)

All agent reasoning, analysis, and recommendations will be powered by Claude:
- Chat Conductor Agent ‚Üí Claude
- Performance Diagnosis Agent ‚Üí Claude
- Budget & Pacing Agent ‚Üí Claude
- Audience & Targeting Agent ‚Üí Claude
- Creative & Inventory Agent ‚Üí Claude

### Semantic Memory ‚úÖ
**Uses:** OpenAI (embeddings only)

When agents learn new patterns or insights:
1. Learning text ‚Üí OpenAI embedding ‚Üí Vector
2. Vector stored in PostgreSQL (pgvector)
3. Future queries use vector similarity search
4. Retrieved memories provided to Claude for context

### Cost Impact

**Typical Usage (1,000 conversations):**
- Claude Opus: ~$20-$400 (main cost, depends on length)
- OpenAI Embeddings: ~$0.02 (negligible)

**Embeddings are extremely cheap:**
- $0.02 per 1 million tokens
- 10,000 learnings ‚âà $0.02

## Priority Logic

When both keys are set:
```
LLM:        Anthropic > OpenAI
Embeddings: OpenAI (required, no alternative)
```

### If You Only Set ANTHROPIC_API_KEY:
- ‚úÖ Agents work (use Claude)
- ‚ùå No semantic memory
- ‚úÖ Session memory works

### If You Only Set OPENAI_API_KEY:
- ‚úÖ Agents work (use GPT-4)
- ‚úÖ Semantic memory works
- ‚úÖ Everything works

### If You Set Both (Recommended):
- ‚úÖ Agents use Claude (best reasoning)
- ‚úÖ Embeddings use OpenAI (required)
- ‚úÖ Full system capabilities
- üí∞ Minimal embedding costs

## Files Modified

1. `backend/src/agents/base.py` - LLM initialization logic
2. `backend/src/memory/vector_store.py` - Embedding initialization
3. `.env.example` - Configuration template
4. `README.md` - Quick start guide
5. `docs/CLAUDE_SETUP.md` - Comprehensive setup guide (new)
6. `docs/API_SETUP_COMPLETE.md` - This file (new)

## Next Steps

1. **Add your API keys** to `.env`
2. **Add Snowflake credentials** to `.env`
3. **Start the system**: `cd infrastructure && docker-compose up -d`
4. **Run migrations**: `docker exec -it dv360-backend alembic upgrade head`
5. **Check logs**: `docker logs dv360-backend`

## Documentation

- **Quick Setup**: See `README.md`
- **Detailed Setup**: See `docs/CLAUDE_SETUP.md`
- **Full Specification**: See `spec.md`
- **Progress**: See `docs/SPRINT2_PROGRESS.md`

## Support

If you encounter issues:
1. Check `docs/CLAUDE_SETUP.md` troubleshooting section
2. Verify API keys are correct (no spaces, correct format)
3. Check logs: `docker logs dv360-backend`
4. Ensure billing is set up on both platforms

---

**Configuration Status:** ‚úÖ Complete and Ready

The system is now configured for optimal performance with Claude reasoning and OpenAI embeddings!
